{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTT4185 Machine learning for Speech technology\n",
    "\n",
    "## Computer assigment 3a: Classification using Deep Neural Networks\n",
    "\n",
    "This assignment assumes that the student has reviewed the material on deep neural networks.\n",
    "\n",
    "In this assignment we will use the high level `Keras` framework together with `Tensorflow` to perform some deep learning experiments.\n",
    "\n",
    "We will be using a small database of phonemes, where each phoneme is represented by the four first formant positions (\"F1\"-\"F4\") and their corresponding bandwidths (\"B1\"-\"B4\"). All numbers are in kHz. In addition, the speaker ID and the gender of the speaker are given for each phoneme.\n",
    "\n",
    "The first few cells of this notebook contain example code to load and extract data, setup a simple network and train a deep neural network for classification. \n",
    "\n",
    "Note that we do not have a test dataset, but only training and validation sets. We do some experiments on the training set and observe the effect on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.17.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.36.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpeakerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>h#</td>\n",
       "      <td>0.701982</td>\n",
       "      <td>2.125440</td>\n",
       "      <td>2.433528</td>\n",
       "      <td>3.530050</td>\n",
       "      <td>0.264459</td>\n",
       "      <td>0.326273</td>\n",
       "      <td>0.300301</td>\n",
       "      <td>0.410096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>q</td>\n",
       "      <td>0.340942</td>\n",
       "      <td>2.594934</td>\n",
       "      <td>2.788244</td>\n",
       "      <td>4.028250</td>\n",
       "      <td>0.282159</td>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.505835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>iy</td>\n",
       "      <td>0.487078</td>\n",
       "      <td>2.605132</td>\n",
       "      <td>3.093409</td>\n",
       "      <td>4.354061</td>\n",
       "      <td>0.174520</td>\n",
       "      <td>0.340025</td>\n",
       "      <td>0.232818</td>\n",
       "      <td>0.413965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>v</td>\n",
       "      <td>0.505536</td>\n",
       "      <td>2.034326</td>\n",
       "      <td>2.804329</td>\n",
       "      <td>4.130655</td>\n",
       "      <td>0.190478</td>\n",
       "      <td>0.307295</td>\n",
       "      <td>0.301741</td>\n",
       "      <td>0.370238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>ih</td>\n",
       "      <td>0.524527</td>\n",
       "      <td>2.055382</td>\n",
       "      <td>2.989248</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>0.164466</td>\n",
       "      <td>0.312337</td>\n",
       "      <td>0.301859</td>\n",
       "      <td>0.362134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>n</td>\n",
       "      <td>0.601591</td>\n",
       "      <td>2.046562</td>\n",
       "      <td>3.251497</td>\n",
       "      <td>4.561420</td>\n",
       "      <td>0.185757</td>\n",
       "      <td>0.334235</td>\n",
       "      <td>0.316704</td>\n",
       "      <td>0.381524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>eh</td>\n",
       "      <td>0.762154</td>\n",
       "      <td>2.127740</td>\n",
       "      <td>3.212496</td>\n",
       "      <td>4.412842</td>\n",
       "      <td>0.207840</td>\n",
       "      <td>0.303633</td>\n",
       "      <td>0.285026</td>\n",
       "      <td>0.384152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>n</td>\n",
       "      <td>0.714553</td>\n",
       "      <td>1.837149</td>\n",
       "      <td>3.218620</td>\n",
       "      <td>5.001730</td>\n",
       "      <td>0.252105</td>\n",
       "      <td>0.311876</td>\n",
       "      <td>0.333318</td>\n",
       "      <td>0.432281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>q</td>\n",
       "      <td>0.619766</td>\n",
       "      <td>2.276717</td>\n",
       "      <td>3.109751</td>\n",
       "      <td>4.658425</td>\n",
       "      <td>0.231525</td>\n",
       "      <td>0.314789</td>\n",
       "      <td>0.406002</td>\n",
       "      <td>0.417538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cjf0</td>\n",
       "      <td>F</td>\n",
       "      <td>ix</td>\n",
       "      <td>0.463761</td>\n",
       "      <td>2.181577</td>\n",
       "      <td>2.859900</td>\n",
       "      <td>4.327639</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.319690</td>\n",
       "      <td>0.291556</td>\n",
       "      <td>0.425367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SpeakerID Gender Phoneme        F1        F2        F3        F4        B1  \\\n",
       "0      cjf0      F      h#  0.701982  2.125440  2.433528  3.530050  0.264459   \n",
       "1      cjf0      F       q  0.340942  2.594934  2.788244  4.028250  0.282159   \n",
       "2      cjf0      F      iy  0.487078  2.605132  3.093409  4.354061  0.174520   \n",
       "3      cjf0      F       v  0.505536  2.034326  2.804329  4.130655  0.190478   \n",
       "4      cjf0      F      ih  0.524527  2.055382  2.989248  4.480000  0.164466   \n",
       "5      cjf0      F       n  0.601591  2.046562  3.251497  4.561420  0.185757   \n",
       "6      cjf0      F      eh  0.762154  2.127740  3.212496  4.412842  0.207840   \n",
       "7      cjf0      F       n  0.714553  1.837149  3.218620  5.001730  0.252105   \n",
       "8      cjf0      F       q  0.619766  2.276717  3.109751  4.658425  0.231525   \n",
       "9      cjf0      F      ix  0.463761  2.181577  2.859900  4.327639  0.170244   \n",
       "\n",
       "         B2        B3        B4  \n",
       "0  0.326273  0.300301  0.410096  \n",
       "1  0.471724  0.310578  0.505835  \n",
       "2  0.340025  0.232818  0.413965  \n",
       "3  0.307295  0.301741  0.370238  \n",
       "4  0.312337  0.301859  0.362134  \n",
       "5  0.334235  0.316704  0.381524  \n",
       "6  0.303633  0.285026  0.384152  \n",
       "7  0.311876  0.333318  0.432281  \n",
       "8  0.314789  0.406002  0.417538  \n",
       "9  0.319690  0.291556  0.425367  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from CSV files \n",
    "rawtrain = pd.read_csv(\"Train.csv\")\n",
    "rawvalid = pd.read_csv(\"Validation.csv\")\n",
    "\n",
    "# Take a peek at the raw data\n",
    "rawtrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be classifying three different vowels. Extract the training and validation data\n",
    "phonemes = [\"ae\", \"ey\", \"ux\"]\n",
    "train = rawtrain[rawtrain[\"Phoneme\"].isin(phonemes)]\n",
    "valid = rawvalid[rawvalid[\"Phoneme\"].isin(phonemes)]\n",
    "trainlabels = [phonemes.index(ph) for ph in train[\"Phoneme\"]]\n",
    "validlabels = [phonemes.index(ph) for ph in valid[\"Phoneme\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to use\n",
    "features = [\"F1\",\"F2\"]\n",
    "\n",
    "# Extract features\n",
    "x_train_raw = train[features]\n",
    "x_valid_raw = valid[features]\n",
    "\n",
    "# Normalize to zero mean\n",
    "x_mean = np.mean(x_train_raw)\n",
    "x_std = np.std(x_train_raw)\n",
    "x_train = x_train_raw - x_mean\n",
    "x_valid = x_valid_raw - x_mean\n",
    "\n",
    "# Fix labels. The \"to_categorical\" call maps integer labels {n}\n",
    "# to a vector of length N (number of labels) with a one in position n\n",
    "y_train = keras.utils.to_categorical(trainlabels, len(phonemes))\n",
    "y_valid = keras.utils.to_categorical(validlabels, len(phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               768       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 1,539\n",
      "Trainable params: 1,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.0644 - accuracy: 0.5791 - val_loss: 1.0350 - val_accuracy: 0.6199\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9848 - accuracy: 0.6709 - val_loss: 0.9796 - val_accuracy: 0.6052\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9171 - accuracy: 0.6709 - val_loss: 0.9309 - val_accuracy: 0.6089\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8634 - accuracy: 0.6727 - val_loss: 0.8941 - val_accuracy: 0.6199\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.6799 - val_loss: 0.8538 - val_accuracy: 0.6310\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7799 - accuracy: 0.6960 - val_loss: 0.8071 - val_accuracy: 0.6605\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7430 - accuracy: 0.7176 - val_loss: 0.7707 - val_accuracy: 0.6716\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.7446 - val_loss: 0.7368 - val_accuracy: 0.6937\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.7464 - val_loss: 0.7095 - val_accuracy: 0.6974\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.7608 - val_loss: 0.6827 - val_accuracy: 0.6974\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7518 - val_loss: 0.6628 - val_accuracy: 0.7011\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7734 - val_loss: 0.6490 - val_accuracy: 0.6937\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7716 - val_loss: 0.6341 - val_accuracy: 0.6937\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7680 - val_loss: 0.6218 - val_accuracy: 0.7011\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7824 - val_loss: 0.6100 - val_accuracy: 0.7232\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7914 - val_loss: 0.6085 - val_accuracy: 0.7159\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7806 - val_loss: 0.6035 - val_accuracy: 0.7269\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8040 - val_loss: 0.5901 - val_accuracy: 0.7306\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.8058 - val_loss: 0.5916 - val_accuracy: 0.7306\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7896 - val_loss: 0.5931 - val_accuracy: 0.7306\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7986 - val_loss: 0.5813 - val_accuracy: 0.7417\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8022 - val_loss: 0.5909 - val_accuracy: 0.7417\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8058 - val_loss: 0.5822 - val_accuracy: 0.7454\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8076 - val_loss: 0.5784 - val_accuracy: 0.7454\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8040 - val_loss: 0.5837 - val_accuracy: 0.7454\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8004 - val_loss: 0.5893 - val_accuracy: 0.7417\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8004 - val_loss: 0.5831 - val_accuracy: 0.7454\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8094 - val_loss: 0.5785 - val_accuracy: 0.7380\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8040 - val_loss: 0.5870 - val_accuracy: 0.7417\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8094 - val_loss: 0.5785 - val_accuracy: 0.7417\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8040 - val_loss: 0.5858 - val_accuracy: 0.7380\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8004 - val_loss: 0.5838 - val_accuracy: 0.7454\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8129 - val_loss: 0.5868 - val_accuracy: 0.7417\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7986 - val_loss: 0.5858 - val_accuracy: 0.7454\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8076 - val_loss: 0.5888 - val_accuracy: 0.7417\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8040 - val_loss: 0.5911 - val_accuracy: 0.7380\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8076 - val_loss: 0.5830 - val_accuracy: 0.7417\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8076 - val_loss: 0.5883 - val_accuracy: 0.7454\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8076 - val_loss: 0.5935 - val_accuracy: 0.7417\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8094 - val_loss: 0.5890 - val_accuracy: 0.7417\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8076 - val_loss: 0.5900 - val_accuracy: 0.7454\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8004 - val_loss: 0.5887 - val_accuracy: 0.7454\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8112 - val_loss: 0.5968 - val_accuracy: 0.7417\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8094 - val_loss: 0.5854 - val_accuracy: 0.7417\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8094 - val_loss: 0.5883 - val_accuracy: 0.7454\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8040 - val_loss: 0.5881 - val_accuracy: 0.7454\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8004 - val_loss: 0.5880 - val_accuracy: 0.7491\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8076 - val_loss: 0.5952 - val_accuracy: 0.7417\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8076 - val_loss: 0.5882 - val_accuracy: 0.7491\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8112 - val_loss: 0.5916 - val_accuracy: 0.7491\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8040 - val_loss: 0.5929 - val_accuracy: 0.7417\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8040 - val_loss: 0.5848 - val_accuracy: 0.7417\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8076 - val_loss: 0.5930 - val_accuracy: 0.7454\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8058 - val_loss: 0.5934 - val_accuracy: 0.7417\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8040 - val_loss: 0.5919 - val_accuracy: 0.7491\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8112 - val_loss: 0.5963 - val_accuracy: 0.7417\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8129 - val_loss: 0.5920 - val_accuracy: 0.7417\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8022 - val_loss: 0.5857 - val_accuracy: 0.7454\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8004 - val_loss: 0.5914 - val_accuracy: 0.7380\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8076 - val_loss: 0.5909 - val_accuracy: 0.7528\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8058 - val_loss: 0.5975 - val_accuracy: 0.7380\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8112 - val_loss: 0.5894 - val_accuracy: 0.7454\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8076 - val_loss: 0.5961 - val_accuracy: 0.7417\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8112 - val_loss: 0.5918 - val_accuracy: 0.7417\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8040 - val_loss: 0.5914 - val_accuracy: 0.7454\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8094 - val_loss: 0.5966 - val_accuracy: 0.7454\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8058 - val_loss: 0.5873 - val_accuracy: 0.7454\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8058 - val_loss: 0.5965 - val_accuracy: 0.7454\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8165 - val_loss: 0.5946 - val_accuracy: 0.7417\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8112 - val_loss: 0.5913 - val_accuracy: 0.7454\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8147 - val_loss: 0.5997 - val_accuracy: 0.7454\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8076 - val_loss: 0.5895 - val_accuracy: 0.7454\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8094 - val_loss: 0.5988 - val_accuracy: 0.7454\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8022 - val_loss: 0.5915 - val_accuracy: 0.7454\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8112 - val_loss: 0.5906 - val_accuracy: 0.7491\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.8112 - val_loss: 0.6025 - val_accuracy: 0.7454\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.8112 - val_loss: 0.5849 - val_accuracy: 0.7454\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8058 - val_loss: 0.5909 - val_accuracy: 0.7454\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8022 - val_loss: 0.5983 - val_accuracy: 0.7417\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8147 - val_loss: 0.5957 - val_accuracy: 0.7417\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.8094 - val_loss: 0.5912 - val_accuracy: 0.7491\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8076 - val_loss: 0.5950 - val_accuracy: 0.7417\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.8076 - val_loss: 0.5949 - val_accuracy: 0.7380\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8058 - val_loss: 0.5943 - val_accuracy: 0.7417\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8112 - val_loss: 0.5982 - val_accuracy: 0.7417\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.8040 - val_loss: 0.5884 - val_accuracy: 0.7491\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8129 - val_loss: 0.5950 - val_accuracy: 0.7454\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.8058 - val_loss: 0.5921 - val_accuracy: 0.7454\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8094 - val_loss: 0.5945 - val_accuracy: 0.7417\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.8147 - val_loss: 0.5943 - val_accuracy: 0.7417\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.8094 - val_loss: 0.5926 - val_accuracy: 0.7417\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8094 - val_loss: 0.5959 - val_accuracy: 0.7454\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8040 - val_loss: 0.5916 - val_accuracy: 0.7417\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8058 - val_loss: 0.5906 - val_accuracy: 0.7454\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.8094 - val_loss: 0.5930 - val_accuracy: 0.7417\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.8076 - val_loss: 0.5988 - val_accuracy: 0.7454\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.8094 - val_loss: 0.5885 - val_accuracy: 0.7491\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8094 - val_loss: 0.5957 - val_accuracy: 0.7417\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8022 - val_loss: 0.5908 - val_accuracy: 0.7454\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.8058 - val_loss: 0.5951 - val_accuracy: 0.7417\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.8040 - val_loss: 0.5936 - val_accuracy: 0.7417\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8129 - val_loss: 0.5935 - val_accuracy: 0.7417\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.8094 - val_loss: 0.5942 - val_accuracy: 0.7417\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8094 - val_loss: 0.5922 - val_accuracy: 0.7417\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8058 - val_loss: 0.5952 - val_accuracy: 0.7417\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8165 - val_loss: 0.5932 - val_accuracy: 0.7417\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8183 - val_loss: 0.5920 - val_accuracy: 0.7417\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.8058 - val_loss: 0.5967 - val_accuracy: 0.7454\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8147 - val_loss: 0.5884 - val_accuracy: 0.7454\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8094 - val_loss: 0.5947 - val_accuracy: 0.7417\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.8112 - val_loss: 0.5918 - val_accuracy: 0.7417\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8147 - val_loss: 0.5916 - val_accuracy: 0.7417\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.8147 - val_loss: 0.5903 - val_accuracy: 0.7417\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8183 - val_loss: 0.6024 - val_accuracy: 0.7454\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8076 - val_loss: 0.5942 - val_accuracy: 0.7417\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8076 - val_loss: 0.5980 - val_accuracy: 0.7454\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.8165 - val_loss: 0.5967 - val_accuracy: 0.7417\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.8165 - val_loss: 0.5862 - val_accuracy: 0.7491\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.8147 - val_loss: 0.5929 - val_accuracy: 0.7417\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8129 - val_loss: 0.5984 - val_accuracy: 0.7417\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.8094 - val_loss: 0.5945 - val_accuracy: 0.7417\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8129 - val_loss: 0.5917 - val_accuracy: 0.7417\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8165 - val_loss: 0.5928 - val_accuracy: 0.7417\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8129 - val_loss: 0.5951 - val_accuracy: 0.7454\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.8040 - val_loss: 0.5923 - val_accuracy: 0.7417\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.8076 - val_loss: 0.5977 - val_accuracy: 0.7417\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8112 - val_loss: 0.5916 - val_accuracy: 0.7417\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8094 - val_loss: 0.5836 - val_accuracy: 0.7454\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.8112 - val_loss: 0.5970 - val_accuracy: 0.7417\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.8094 - val_loss: 0.5961 - val_accuracy: 0.7417\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8129 - val_loss: 0.5903 - val_accuracy: 0.7417\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.8040 - val_loss: 0.5988 - val_accuracy: 0.7380\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8094 - val_loss: 0.5953 - val_accuracy: 0.7417\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8076 - val_loss: 0.5984 - val_accuracy: 0.7417\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8183 - val_loss: 0.5909 - val_accuracy: 0.7417\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.8129 - val_loss: 0.5930 - val_accuracy: 0.7417\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8058 - val_loss: 0.5940 - val_accuracy: 0.7417\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.8129 - val_loss: 0.5971 - val_accuracy: 0.7417\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8183 - val_loss: 0.5958 - val_accuracy: 0.7417\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.8076 - val_loss: 0.5945 - val_accuracy: 0.7417\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8165 - val_loss: 0.5935 - val_accuracy: 0.7417\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.8112 - val_loss: 0.6045 - val_accuracy: 0.7417\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.8165 - val_loss: 0.5913 - val_accuracy: 0.7417\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8112 - val_loss: 0.5924 - val_accuracy: 0.7417\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8112 - val_loss: 0.5986 - val_accuracy: 0.7417\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.8201 - val_loss: 0.5929 - val_accuracy: 0.7417\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.8112 - val_loss: 0.5922 - val_accuracy: 0.7417\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8094 - val_loss: 0.5908 - val_accuracy: 0.7454\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8076 - val_loss: 0.5919 - val_accuracy: 0.7417\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8112 - val_loss: 0.5999 - val_accuracy: 0.7417\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.8076 - val_loss: 0.5908 - val_accuracy: 0.7417\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8129 - val_loss: 0.5967 - val_accuracy: 0.7417\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8129 - val_loss: 0.5986 - val_accuracy: 0.7417\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.8112 - val_loss: 0.5876 - val_accuracy: 0.7417\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8094 - val_loss: 0.5931 - val_accuracy: 0.7417\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.8076 - val_loss: 0.5987 - val_accuracy: 0.7417\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8183 - val_loss: 0.5945 - val_accuracy: 0.7454\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.8183 - val_loss: 0.5970 - val_accuracy: 0.7417\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8112 - val_loss: 0.5918 - val_accuracy: 0.7454\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.8112 - val_loss: 0.5964 - val_accuracy: 0.7417\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.8129 - val_loss: 0.5934 - val_accuracy: 0.7417\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8165 - val_loss: 0.5942 - val_accuracy: 0.7417\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.8129 - val_loss: 0.5926 - val_accuracy: 0.7417\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.8094 - val_loss: 0.5999 - val_accuracy: 0.7417\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.8112 - val_loss: 0.5938 - val_accuracy: 0.7417\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8112 - val_loss: 0.5942 - val_accuracy: 0.7454\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.8112 - val_loss: 0.5913 - val_accuracy: 0.7454\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.8094 - val_loss: 0.5962 - val_accuracy: 0.7417\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.8094 - val_loss: 0.6051 - val_accuracy: 0.7417\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8147 - val_loss: 0.5903 - val_accuracy: 0.7417\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8201 - val_loss: 0.5926 - val_accuracy: 0.7417\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.8129 - val_loss: 0.5933 - val_accuracy: 0.7417\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.8129 - val_loss: 0.5953 - val_accuracy: 0.7417\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8040 - val_loss: 0.6006 - val_accuracy: 0.7417\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8147 - val_loss: 0.5897 - val_accuracy: 0.7417\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.8094 - val_loss: 0.5984 - val_accuracy: 0.7417\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8165 - val_loss: 0.5980 - val_accuracy: 0.7417\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8129 - val_loss: 0.5962 - val_accuracy: 0.7380\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.8147 - val_loss: 0.5988 - val_accuracy: 0.7417\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8165 - val_loss: 0.5953 - val_accuracy: 0.7417\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8165 - val_loss: 0.5910 - val_accuracy: 0.7417\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8201 - val_loss: 0.5965 - val_accuracy: 0.7417\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.8076 - val_loss: 0.6030 - val_accuracy: 0.7417\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8094 - val_loss: 0.5921 - val_accuracy: 0.7417\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.8201 - val_loss: 0.5955 - val_accuracy: 0.7417\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8129 - val_loss: 0.6014 - val_accuracy: 0.7417\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8112 - val_loss: 0.5951 - val_accuracy: 0.7417\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8165 - val_loss: 0.5941 - val_accuracy: 0.7417\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8112 - val_loss: 0.5989 - val_accuracy: 0.7417\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8147 - val_loss: 0.5996 - val_accuracy: 0.7417\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.8129 - val_loss: 0.5963 - val_accuracy: 0.7417\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8201 - val_loss: 0.5964 - val_accuracy: 0.7454\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.8094 - val_loss: 0.6021 - val_accuracy: 0.7417\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.8112 - val_loss: 0.5965 - val_accuracy: 0.7417\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8147 - val_loss: 0.5977 - val_accuracy: 0.7417\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.8112 - val_loss: 0.5922 - val_accuracy: 0.7417\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8147 - val_loss: 0.6053 - val_accuracy: 0.7417\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8183 - val_loss: 0.5982 - val_accuracy: 0.7454\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.8201 - val_loss: 0.5980 - val_accuracy: 0.7417\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.8129 - val_loss: 0.5915 - val_accuracy: 0.7417\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8112 - val_loss: 0.5995 - val_accuracy: 0.7417\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8094 - val_loss: 0.5910 - val_accuracy: 0.7417\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.8183 - val_loss: 0.5922 - val_accuracy: 0.7454\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.8129 - val_loss: 0.5991 - val_accuracy: 0.7417\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.8183 - val_loss: 0.5931 - val_accuracy: 0.7417\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8147 - val_loss: 0.5947 - val_accuracy: 0.7454\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8129 - val_loss: 0.6010 - val_accuracy: 0.7417\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8129 - val_loss: 0.5958 - val_accuracy: 0.7417\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8183 - val_loss: 0.5986 - val_accuracy: 0.7417\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.8112 - val_loss: 0.5980 - val_accuracy: 0.7417\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8112 - val_loss: 0.5914 - val_accuracy: 0.7417\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8201 - val_loss: 0.5931 - val_accuracy: 0.7417\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8165 - val_loss: 0.5994 - val_accuracy: 0.7417\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8129 - val_loss: 0.5982 - val_accuracy: 0.7417\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.8094 - val_loss: 0.5931 - val_accuracy: 0.7454\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8094 - val_loss: 0.6009 - val_accuracy: 0.7417\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8165 - val_loss: 0.5969 - val_accuracy: 0.7454\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8076 - val_loss: 0.5976 - val_accuracy: 0.7417\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8094 - val_loss: 0.5956 - val_accuracy: 0.7454\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8129 - val_loss: 0.5946 - val_accuracy: 0.7454\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8219 - val_loss: 0.5992 - val_accuracy: 0.7454\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8147 - val_loss: 0.5952 - val_accuracy: 0.7454\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.8076 - val_loss: 0.5914 - val_accuracy: 0.7491\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.8147 - val_loss: 0.5980 - val_accuracy: 0.7454\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8183 - val_loss: 0.5977 - val_accuracy: 0.7417\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8129 - val_loss: 0.6002 - val_accuracy: 0.7417\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8147 - val_loss: 0.5998 - val_accuracy: 0.7417\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8112 - val_loss: 0.5973 - val_accuracy: 0.7417\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.8147 - val_loss: 0.6013 - val_accuracy: 0.7454\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8129 - val_loss: 0.5921 - val_accuracy: 0.7491\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8201 - val_loss: 0.6028 - val_accuracy: 0.7454\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.8147 - val_loss: 0.5958 - val_accuracy: 0.7454\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.8129 - val_loss: 0.6038 - val_accuracy: 0.7417\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8201 - val_loss: 0.5974 - val_accuracy: 0.7454\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8129 - val_loss: 0.5982 - val_accuracy: 0.7417\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8129 - val_loss: 0.6048 - val_accuracy: 0.7417\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8129 - val_loss: 0.5963 - val_accuracy: 0.7454\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8129 - val_loss: 0.5976 - val_accuracy: 0.7380\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8094 - val_loss: 0.5934 - val_accuracy: 0.7454\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8147 - val_loss: 0.6054 - val_accuracy: 0.7380\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8129 - val_loss: 0.5984 - val_accuracy: 0.7380\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8165 - val_loss: 0.5977 - val_accuracy: 0.7454\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8165 - val_loss: 0.6026 - val_accuracy: 0.7454\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8112 - val_loss: 0.5992 - val_accuracy: 0.7454\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8129 - val_loss: 0.6019 - val_accuracy: 0.7417\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8112 - val_loss: 0.5925 - val_accuracy: 0.7491\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.8147 - val_loss: 0.6059 - val_accuracy: 0.7417\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.8147 - val_loss: 0.5963 - val_accuracy: 0.7454\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8165 - val_loss: 0.6056 - val_accuracy: 0.7454\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8147 - val_loss: 0.5973 - val_accuracy: 0.7454\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8147 - val_loss: 0.5996 - val_accuracy: 0.7454\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8129 - val_loss: 0.6001 - val_accuracy: 0.7417\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8165 - val_loss: 0.6049 - val_accuracy: 0.7454\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.8147 - val_loss: 0.5950 - val_accuracy: 0.7454\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8165 - val_loss: 0.5949 - val_accuracy: 0.7454\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.8129 - val_loss: 0.6039 - val_accuracy: 0.7417\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.8112 - val_loss: 0.5998 - val_accuracy: 0.7454\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.8147 - val_loss: 0.5997 - val_accuracy: 0.7454\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8129 - val_loss: 0.5962 - val_accuracy: 0.7454\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8129 - val_loss: 0.6039 - val_accuracy: 0.7417\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8147 - val_loss: 0.5951 - val_accuracy: 0.7454\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8165 - val_loss: 0.6037 - val_accuracy: 0.7380\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8112 - val_loss: 0.6049 - val_accuracy: 0.7417\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8165 - val_loss: 0.5887 - val_accuracy: 0.7454\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8165 - val_loss: 0.6023 - val_accuracy: 0.7380\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8147 - val_loss: 0.5998 - val_accuracy: 0.7417\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8165 - val_loss: 0.5958 - val_accuracy: 0.7454\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8129 - val_loss: 0.6056 - val_accuracy: 0.7380\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8147 - val_loss: 0.5926 - val_accuracy: 0.7454\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8165 - val_loss: 0.6029 - val_accuracy: 0.7454\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.8147 - val_loss: 0.6060 - val_accuracy: 0.7454\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8129 - val_loss: 0.5930 - val_accuracy: 0.7454\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8165 - val_loss: 0.6044 - val_accuracy: 0.7380\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8147 - val_loss: 0.6043 - val_accuracy: 0.7454\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8112 - val_loss: 0.5921 - val_accuracy: 0.7491\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8183 - val_loss: 0.6033 - val_accuracy: 0.7454\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8165 - val_loss: 0.6013 - val_accuracy: 0.7380\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8147 - val_loss: 0.6066 - val_accuracy: 0.7454\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.8129 - val_loss: 0.6002 - val_accuracy: 0.7454\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8129 - val_loss: 0.6039 - val_accuracy: 0.7454\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8183 - val_loss: 0.6004 - val_accuracy: 0.7454\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8112 - val_loss: 0.5983 - val_accuracy: 0.7454\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8165 - val_loss: 0.5992 - val_accuracy: 0.7454\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8165 - val_loss: 0.5979 - val_accuracy: 0.7454\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8129 - val_loss: 0.6056 - val_accuracy: 0.7491\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8112 - val_loss: 0.6039 - val_accuracy: 0.7380\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8183 - val_loss: 0.5999 - val_accuracy: 0.7417\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8147 - val_loss: 0.6022 - val_accuracy: 0.7380\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8183 - val_loss: 0.6025 - val_accuracy: 0.7454\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.8165 - val_loss: 0.5995 - val_accuracy: 0.7454\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8219 - val_loss: 0.5963 - val_accuracy: 0.7454\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8129 - val_loss: 0.6050 - val_accuracy: 0.7380\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8183 - val_loss: 0.6056 - val_accuracy: 0.7454\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8129 - val_loss: 0.6032 - val_accuracy: 0.7454\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8147 - val_loss: 0.5968 - val_accuracy: 0.7454\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8165 - val_loss: 0.5982 - val_accuracy: 0.7454\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8147 - val_loss: 0.5963 - val_accuracy: 0.7491\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8165 - val_loss: 0.6022 - val_accuracy: 0.7380\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8183 - val_loss: 0.5960 - val_accuracy: 0.7491\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8219 - val_loss: 0.6003 - val_accuracy: 0.7454\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8183 - val_loss: 0.6046 - val_accuracy: 0.7417\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8147 - val_loss: 0.6062 - val_accuracy: 0.7454\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8129 - val_loss: 0.5981 - val_accuracy: 0.7454\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8165 - val_loss: 0.6069 - val_accuracy: 0.7417\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8165 - val_loss: 0.6006 - val_accuracy: 0.7454\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8129 - val_loss: 0.5976 - val_accuracy: 0.7491\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8112 - val_loss: 0.6052 - val_accuracy: 0.7454\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8147 - val_loss: 0.5998 - val_accuracy: 0.7491\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8147 - val_loss: 0.6028 - val_accuracy: 0.7491\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8201 - val_loss: 0.5941 - val_accuracy: 0.7528\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8094 - val_loss: 0.6043 - val_accuracy: 0.7454\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8076 - val_loss: 0.5948 - val_accuracy: 0.7491\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8165 - val_loss: 0.6076 - val_accuracy: 0.7417\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8165 - val_loss: 0.6002 - val_accuracy: 0.7454\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8183 - val_loss: 0.6031 - val_accuracy: 0.7454\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8165 - val_loss: 0.6051 - val_accuracy: 0.7380\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8201 - val_loss: 0.6031 - val_accuracy: 0.7417\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8112 - val_loss: 0.6058 - val_accuracy: 0.7343\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8165 - val_loss: 0.6016 - val_accuracy: 0.7454\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8147 - val_loss: 0.6118 - val_accuracy: 0.7417\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8147 - val_loss: 0.5934 - val_accuracy: 0.7454\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8147 - val_loss: 0.6077 - val_accuracy: 0.7380\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8112 - val_loss: 0.6042 - val_accuracy: 0.7417\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8147 - val_loss: 0.6012 - val_accuracy: 0.7417\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8147 - val_loss: 0.6109 - val_accuracy: 0.7380\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8219 - val_loss: 0.5966 - val_accuracy: 0.7491\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8147 - val_loss: 0.5999 - val_accuracy: 0.7454\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8112 - val_loss: 0.6067 - val_accuracy: 0.7491\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8183 - val_loss: 0.5994 - val_accuracy: 0.7491\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8165 - val_loss: 0.6046 - val_accuracy: 0.7417\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8129 - val_loss: 0.6041 - val_accuracy: 0.7491\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8147 - val_loss: 0.6011 - val_accuracy: 0.7454\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8183 - val_loss: 0.6069 - val_accuracy: 0.7491\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8201 - val_loss: 0.6041 - val_accuracy: 0.7417\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8201 - val_loss: 0.6015 - val_accuracy: 0.7454\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8183 - val_loss: 0.6024 - val_accuracy: 0.7491\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8112 - val_loss: 0.6075 - val_accuracy: 0.7417\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8147 - val_loss: 0.6079 - val_accuracy: 0.7454\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8201 - val_loss: 0.6019 - val_accuracy: 0.7454\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8147 - val_loss: 0.6022 - val_accuracy: 0.7491\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8183 - val_loss: 0.6018 - val_accuracy: 0.7454\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8165 - val_loss: 0.6019 - val_accuracy: 0.7454\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8183 - val_loss: 0.6037 - val_accuracy: 0.7417\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8165 - val_loss: 0.6060 - val_accuracy: 0.7491\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8147 - val_loss: 0.6112 - val_accuracy: 0.7417\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8165 - val_loss: 0.6067 - val_accuracy: 0.7454\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.8219 - val_loss: 0.6022 - val_accuracy: 0.7491\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8165 - val_loss: 0.5996 - val_accuracy: 0.7491\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8165 - val_loss: 0.6031 - val_accuracy: 0.7454\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8147 - val_loss: 0.6095 - val_accuracy: 0.7454\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8183 - val_loss: 0.5991 - val_accuracy: 0.7491\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8165 - val_loss: 0.6114 - val_accuracy: 0.7417\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8183 - val_loss: 0.6064 - val_accuracy: 0.7491\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8201 - val_loss: 0.6019 - val_accuracy: 0.7454\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8165 - val_loss: 0.6027 - val_accuracy: 0.7454\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8183 - val_loss: 0.6107 - val_accuracy: 0.7417\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8183 - val_loss: 0.5985 - val_accuracy: 0.7491\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8237 - val_loss: 0.5992 - val_accuracy: 0.7491\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8165 - val_loss: 0.6129 - val_accuracy: 0.7417\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8147 - val_loss: 0.5985 - val_accuracy: 0.7491\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8219 - val_loss: 0.6066 - val_accuracy: 0.7454\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8112 - val_loss: 0.6027 - val_accuracy: 0.7491\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8183 - val_loss: 0.6149 - val_accuracy: 0.7417\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8183 - val_loss: 0.5944 - val_accuracy: 0.7528\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8201 - val_loss: 0.6078 - val_accuracy: 0.7417\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8165 - val_loss: 0.6084 - val_accuracy: 0.7417\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8219 - val_loss: 0.6022 - val_accuracy: 0.7491\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8237 - val_loss: 0.6075 - val_accuracy: 0.7417\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8183 - val_loss: 0.6101 - val_accuracy: 0.7417\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8129 - val_loss: 0.6063 - val_accuracy: 0.7454\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8255 - val_loss: 0.6021 - val_accuracy: 0.7454\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8255 - val_loss: 0.6076 - val_accuracy: 0.7417\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8147 - val_loss: 0.6059 - val_accuracy: 0.7491\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8237 - val_loss: 0.6063 - val_accuracy: 0.7454\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8219 - val_loss: 0.6048 - val_accuracy: 0.7491\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8183 - val_loss: 0.6080 - val_accuracy: 0.7454\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8165 - val_loss: 0.6059 - val_accuracy: 0.7454\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8183 - val_loss: 0.5993 - val_accuracy: 0.7454\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8201 - val_loss: 0.6083 - val_accuracy: 0.7380\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8201 - val_loss: 0.6096 - val_accuracy: 0.7454\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8201 - val_loss: 0.6114 - val_accuracy: 0.7417\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8112 - val_loss: 0.6035 - val_accuracy: 0.7417\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8219 - val_loss: 0.6041 - val_accuracy: 0.7454\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8147 - val_loss: 0.6129 - val_accuracy: 0.7380\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8147 - val_loss: 0.6023 - val_accuracy: 0.7491\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8201 - val_loss: 0.6071 - val_accuracy: 0.7454\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8201 - val_loss: 0.6106 - val_accuracy: 0.7454\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8219 - val_loss: 0.6025 - val_accuracy: 0.7491\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8201 - val_loss: 0.6042 - val_accuracy: 0.7454\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8255 - val_loss: 0.5996 - val_accuracy: 0.7491\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8165 - val_loss: 0.6128 - val_accuracy: 0.7343\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8183 - val_loss: 0.6005 - val_accuracy: 0.7491\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8255 - val_loss: 0.6062 - val_accuracy: 0.7417\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8165 - val_loss: 0.6078 - val_accuracy: 0.7454\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8201 - val_loss: 0.6045 - val_accuracy: 0.7454\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8165 - val_loss: 0.6056 - val_accuracy: 0.7491\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8237 - val_loss: 0.6041 - val_accuracy: 0.7454\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8201 - val_loss: 0.6056 - val_accuracy: 0.7454\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8201 - val_loss: 0.6027 - val_accuracy: 0.7491\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8183 - val_loss: 0.6066 - val_accuracy: 0.7454\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8183 - val_loss: 0.6108 - val_accuracy: 0.7454\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.8183 - val_loss: 0.6044 - val_accuracy: 0.7491\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8219 - val_loss: 0.6037 - val_accuracy: 0.7454\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8291 - val_loss: 0.6089 - val_accuracy: 0.7454\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8183 - val_loss: 0.6047 - val_accuracy: 0.7454\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8201 - val_loss: 0.6061 - val_accuracy: 0.7454\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8183 - val_loss: 0.6088 - val_accuracy: 0.7454\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8165 - val_loss: 0.6014 - val_accuracy: 0.7454\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8255 - val_loss: 0.6069 - val_accuracy: 0.7454\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8255 - val_loss: 0.6062 - val_accuracy: 0.7491\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8219 - val_loss: 0.6123 - val_accuracy: 0.7454\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8219 - val_loss: 0.5978 - val_accuracy: 0.7491\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8201 - val_loss: 0.6060 - val_accuracy: 0.7417\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8255 - val_loss: 0.6024 - val_accuracy: 0.7491\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8201 - val_loss: 0.6053 - val_accuracy: 0.7491\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8255 - val_loss: 0.6040 - val_accuracy: 0.7454\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.8201 - val_loss: 0.6096 - val_accuracy: 0.7454\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8291 - val_loss: 0.6022 - val_accuracy: 0.7454\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8165 - val_loss: 0.6136 - val_accuracy: 0.7380\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8219 - val_loss: 0.6022 - val_accuracy: 0.7454\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8237 - val_loss: 0.6063 - val_accuracy: 0.7454\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8219 - val_loss: 0.6053 - val_accuracy: 0.7454\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8219 - val_loss: 0.6051 - val_accuracy: 0.7454\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8183 - val_loss: 0.6044 - val_accuracy: 0.7454\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8219 - val_loss: 0.6066 - val_accuracy: 0.7454\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8255 - val_loss: 0.6072 - val_accuracy: 0.7454\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8183 - val_loss: 0.6097 - val_accuracy: 0.7417\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8219 - val_loss: 0.6007 - val_accuracy: 0.7491\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8129 - val_loss: 0.6052 - val_accuracy: 0.7491\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8219 - val_loss: 0.6044 - val_accuracy: 0.7454\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8255 - val_loss: 0.6029 - val_accuracy: 0.7491\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8219 - val_loss: 0.6075 - val_accuracy: 0.7454\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8201 - val_loss: 0.6117 - val_accuracy: 0.7417\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8165 - val_loss: 0.6031 - val_accuracy: 0.7454\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8183 - val_loss: 0.6023 - val_accuracy: 0.7454\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8165 - val_loss: 0.6129 - val_accuracy: 0.7380\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8201 - val_loss: 0.6108 - val_accuracy: 0.7454\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8237 - val_loss: 0.6029 - val_accuracy: 0.7454\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8219 - val_loss: 0.6066 - val_accuracy: 0.7454\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8237 - val_loss: 0.6103 - val_accuracy: 0.7454\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8255 - val_loss: 0.6076 - val_accuracy: 0.7454\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8147 - val_loss: 0.6040 - val_accuracy: 0.7454\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8201 - val_loss: 0.6080 - val_accuracy: 0.7454\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.8255 - val_loss: 0.6085 - val_accuracy: 0.7454\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8237 - val_loss: 0.6049 - val_accuracy: 0.7454\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.8201 - val_loss: 0.6136 - val_accuracy: 0.7454\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8165 - val_loss: 0.5976 - val_accuracy: 0.7454\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8219 - val_loss: 0.6054 - val_accuracy: 0.7454\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8237 - val_loss: 0.6037 - val_accuracy: 0.7454\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8219 - val_loss: 0.6119 - val_accuracy: 0.7454\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8219 - val_loss: 0.6076 - val_accuracy: 0.7491\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8147 - val_loss: 0.6087 - val_accuracy: 0.7454\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8165 - val_loss: 0.6107 - val_accuracy: 0.7454\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.8147 - val_loss: 0.6026 - val_accuracy: 0.7454\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.8201 - val_loss: 0.6177 - val_accuracy: 0.7380\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8147 - val_loss: 0.6003 - val_accuracy: 0.7454\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8201 - val_loss: 0.6072 - val_accuracy: 0.7491\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8201 - val_loss: 0.6050 - val_accuracy: 0.7454\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8237 - val_loss: 0.6076 - val_accuracy: 0.7491\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.8255 - val_loss: 0.6023 - val_accuracy: 0.7454\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.8237 - val_loss: 0.6080 - val_accuracy: 0.7454\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.8183 - val_loss: 0.6101 - val_accuracy: 0.7454\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8237 - val_loss: 0.6073 - val_accuracy: 0.7417\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.8237 - val_loss: 0.6072 - val_accuracy: 0.7454\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.8237 - val_loss: 0.6088 - val_accuracy: 0.7454\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8147 - val_loss: 0.6091 - val_accuracy: 0.7454\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8237 - val_loss: 0.6087 - val_accuracy: 0.7454\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8183 - val_loss: 0.6118 - val_accuracy: 0.7454\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8219 - val_loss: 0.6024 - val_accuracy: 0.7454\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8219 - val_loss: 0.6040 - val_accuracy: 0.7491\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8255 - val_loss: 0.6030 - val_accuracy: 0.7454\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8201 - val_loss: 0.6109 - val_accuracy: 0.7454\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8255 - val_loss: 0.6059 - val_accuracy: 0.7454\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8237 - val_loss: 0.6074 - val_accuracy: 0.7454\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8219 - val_loss: 0.6058 - val_accuracy: 0.7454\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8237 - val_loss: 0.6053 - val_accuracy: 0.7454\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8201 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8183 - val_loss: 0.6055 - val_accuracy: 0.7454\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8237 - val_loss: 0.6169 - val_accuracy: 0.7380\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8219 - val_loss: 0.5983 - val_accuracy: 0.7417\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8237 - val_loss: 0.6086 - val_accuracy: 0.7454\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8183 - val_loss: 0.6071 - val_accuracy: 0.7454\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8237 - val_loss: 0.6094 - val_accuracy: 0.7454\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.8219 - val_loss: 0.6121 - val_accuracy: 0.7454\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8219 - val_loss: 0.6132 - val_accuracy: 0.7454\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8165 - val_loss: 0.5968 - val_accuracy: 0.7454\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.8183 - val_loss: 0.6055 - val_accuracy: 0.7491\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8165 - val_loss: 0.6055 - val_accuracy: 0.7454\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8183 - val_loss: 0.6070 - val_accuracy: 0.7491\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8201 - val_loss: 0.6102 - val_accuracy: 0.7454\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8219 - val_loss: 0.6019 - val_accuracy: 0.7454\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8219 - val_loss: 0.6105 - val_accuracy: 0.7454\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8183 - val_loss: 0.6069 - val_accuracy: 0.7491\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8183 - val_loss: 0.6151 - val_accuracy: 0.7380\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8165 - val_loss: 0.6022 - val_accuracy: 0.7454\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8183 - val_loss: 0.6033 - val_accuracy: 0.7454\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.8255 - val_loss: 0.6121 - val_accuracy: 0.7454\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8201 - val_loss: 0.6129 - val_accuracy: 0.7417\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8219 - val_loss: 0.6113 - val_accuracy: 0.7454\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8219 - val_loss: 0.6052 - val_accuracy: 0.7454\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8201 - val_loss: 0.6055 - val_accuracy: 0.7454\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.8219 - val_loss: 0.6072 - val_accuracy: 0.7454\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8183 - val_loss: 0.6086 - val_accuracy: 0.7454\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8255 - val_loss: 0.6123 - val_accuracy: 0.7454\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8237 - val_loss: 0.6138 - val_accuracy: 0.7417\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8273 - val_loss: 0.6099 - val_accuracy: 0.7454\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.8219 - val_loss: 0.6069 - val_accuracy: 0.7454\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8237 - val_loss: 0.6080 - val_accuracy: 0.7454\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.8237 - val_loss: 0.6060 - val_accuracy: 0.7454\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8219 - val_loss: 0.6076 - val_accuracy: 0.7454\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8255 - val_loss: 0.6058 - val_accuracy: 0.7454\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8201 - val_loss: 0.6127 - val_accuracy: 0.7380\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.8183 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.8255 - val_loss: 0.6057 - val_accuracy: 0.7454\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8237 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8291 - val_loss: 0.6148 - val_accuracy: 0.7454\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8201 - val_loss: 0.6046 - val_accuracy: 0.7454\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8219 - val_loss: 0.6131 - val_accuracy: 0.7454\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8201 - val_loss: 0.6097 - val_accuracy: 0.7454\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8201 - val_loss: 0.6145 - val_accuracy: 0.7454\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8201 - val_loss: 0.6079 - val_accuracy: 0.7454\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8237 - val_loss: 0.6040 - val_accuracy: 0.7454\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8219 - val_loss: 0.6104 - val_accuracy: 0.7454\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8183 - val_loss: 0.6220 - val_accuracy: 0.7380\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.8237 - val_loss: 0.5996 - val_accuracy: 0.7454\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8201 - val_loss: 0.6125 - val_accuracy: 0.7454\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8237 - val_loss: 0.6079 - val_accuracy: 0.7454\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.8255 - val_loss: 0.6103 - val_accuracy: 0.7454\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8219 - val_loss: 0.6028 - val_accuracy: 0.7491\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8237 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8273 - val_loss: 0.6089 - val_accuracy: 0.7454\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.8219 - val_loss: 0.6109 - val_accuracy: 0.7454\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.8237 - val_loss: 0.6015 - val_accuracy: 0.7454\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8183 - val_loss: 0.6141 - val_accuracy: 0.7454\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8201 - val_loss: 0.6052 - val_accuracy: 0.7454\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8273 - val_loss: 0.6092 - val_accuracy: 0.7454\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8219 - val_loss: 0.6105 - val_accuracy: 0.7454\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8255 - val_loss: 0.6041 - val_accuracy: 0.7454\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8201 - val_loss: 0.6113 - val_accuracy: 0.7454\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8183 - val_loss: 0.6056 - val_accuracy: 0.7454\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8201 - val_loss: 0.6199 - val_accuracy: 0.7380\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8183 - val_loss: 0.6064 - val_accuracy: 0.7454\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8273 - val_loss: 0.6058 - val_accuracy: 0.7454\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8237 - val_loss: 0.6060 - val_accuracy: 0.7454\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8201 - val_loss: 0.6066 - val_accuracy: 0.7454\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8201 - val_loss: 0.6101 - val_accuracy: 0.7454\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8219 - val_loss: 0.6122 - val_accuracy: 0.7454\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8165 - val_loss: 0.6001 - val_accuracy: 0.7454\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8219 - val_loss: 0.6171 - val_accuracy: 0.7491\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8147 - val_loss: 0.6064 - val_accuracy: 0.7454\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8255 - val_loss: 0.6077 - val_accuracy: 0.7454\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8219 - val_loss: 0.6115 - val_accuracy: 0.7454\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4434 - accuracy: 0.8201 - val_loss: 0.6075 - val_accuracy: 0.7454\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8237 - val_loss: 0.6091 - val_accuracy: 0.7454\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8237 - val_loss: 0.6107 - val_accuracy: 0.7454\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8237 - val_loss: 0.6073 - val_accuracy: 0.7454\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8237 - val_loss: 0.6118 - val_accuracy: 0.7454\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8219 - val_loss: 0.6072 - val_accuracy: 0.7417\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8219 - val_loss: 0.6155 - val_accuracy: 0.7454\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8219 - val_loss: 0.6030 - val_accuracy: 0.7454\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8237 - val_loss: 0.6105 - val_accuracy: 0.7454\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.8255 - val_loss: 0.6073 - val_accuracy: 0.7454\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8219 - val_loss: 0.6116 - val_accuracy: 0.7454\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8255 - val_loss: 0.6035 - val_accuracy: 0.7454\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8201 - val_loss: 0.6115 - val_accuracy: 0.7454\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.8255 - val_loss: 0.6087 - val_accuracy: 0.7454\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8273 - val_loss: 0.6121 - val_accuracy: 0.7454\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8219 - val_loss: 0.6177 - val_accuracy: 0.7454\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8219 - val_loss: 0.6087 - val_accuracy: 0.7454\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8273 - val_loss: 0.6095 - val_accuracy: 0.7417\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8219 - val_loss: 0.6194 - val_accuracy: 0.7417\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8255 - val_loss: 0.6070 - val_accuracy: 0.7454\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8201 - val_loss: 0.6238 - val_accuracy: 0.7380\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.8273 - val_loss: 0.6047 - val_accuracy: 0.7454\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8219 - val_loss: 0.6114 - val_accuracy: 0.7454\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8255 - val_loss: 0.6043 - val_accuracy: 0.7454\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8255 - val_loss: 0.6067 - val_accuracy: 0.7454\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8219 - val_loss: 0.6121 - val_accuracy: 0.7454\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.8237 - val_loss: 0.6141 - val_accuracy: 0.7454\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8201 - val_loss: 0.6084 - val_accuracy: 0.7454\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8273 - val_loss: 0.6048 - val_accuracy: 0.7454\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8273 - val_loss: 0.6121 - val_accuracy: 0.7454\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8183 - val_loss: 0.6128 - val_accuracy: 0.7454\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8273 - val_loss: 0.6097 - val_accuracy: 0.7454\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8201 - val_loss: 0.6075 - val_accuracy: 0.7454\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8255 - val_loss: 0.6118 - val_accuracy: 0.7454\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8201 - val_loss: 0.6139 - val_accuracy: 0.7454\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8219 - val_loss: 0.6057 - val_accuracy: 0.7454\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8219 - val_loss: 0.6168 - val_accuracy: 0.7491\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8201 - val_loss: 0.6152 - val_accuracy: 0.7454\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8237 - val_loss: 0.6116 - val_accuracy: 0.7454\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8237 - val_loss: 0.6116 - val_accuracy: 0.7454\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8201 - val_loss: 0.6096 - val_accuracy: 0.7454\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8273 - val_loss: 0.6055 - val_accuracy: 0.7454\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8291 - val_loss: 0.6115 - val_accuracy: 0.7454\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.8219 - val_loss: 0.6167 - val_accuracy: 0.7417\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.8237 - val_loss: 0.6085 - val_accuracy: 0.7454\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8219 - val_loss: 0.6005 - val_accuracy: 0.7491\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8255 - val_loss: 0.6125 - val_accuracy: 0.7454\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8219 - val_loss: 0.6075 - val_accuracy: 0.7454\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8147 - val_loss: 0.6214 - val_accuracy: 0.7417\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8237 - val_loss: 0.5996 - val_accuracy: 0.7454\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8255 - val_loss: 0.6095 - val_accuracy: 0.7454\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8219 - val_loss: 0.6109 - val_accuracy: 0.7454\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8219 - val_loss: 0.6169 - val_accuracy: 0.7491\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8201 - val_loss: 0.6113 - val_accuracy: 0.7454\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.8237 - val_loss: 0.6068 - val_accuracy: 0.7454\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.8255 - val_loss: 0.6132 - val_accuracy: 0.7454\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8165 - val_loss: 0.6084 - val_accuracy: 0.7454\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8237 - val_loss: 0.6118 - val_accuracy: 0.7454\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8201 - val_loss: 0.6145 - val_accuracy: 0.7491\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8255 - val_loss: 0.6088 - val_accuracy: 0.7454\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8219 - val_loss: 0.6107 - val_accuracy: 0.7454\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8255 - val_loss: 0.6084 - val_accuracy: 0.7454\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8183 - val_loss: 0.6177 - val_accuracy: 0.7417\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.8219 - val_loss: 0.6102 - val_accuracy: 0.7454\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8237 - val_loss: 0.6027 - val_accuracy: 0.7454\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8237 - val_loss: 0.6149 - val_accuracy: 0.7454\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8183 - val_loss: 0.6085 - val_accuracy: 0.7454\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8237 - val_loss: 0.6191 - val_accuracy: 0.7454\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8219 - val_loss: 0.6110 - val_accuracy: 0.7454\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8201 - val_loss: 0.6088 - val_accuracy: 0.7454\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.8237 - val_loss: 0.6131 - val_accuracy: 0.7454\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8201 - val_loss: 0.6093 - val_accuracy: 0.7491\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8237 - val_loss: 0.6143 - val_accuracy: 0.7454\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8291 - val_loss: 0.6100 - val_accuracy: 0.7454\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8327 - val_loss: 0.6115 - val_accuracy: 0.7454\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8219 - val_loss: 0.6101 - val_accuracy: 0.7454\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8219 - val_loss: 0.6144 - val_accuracy: 0.7491\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8255 - val_loss: 0.6025 - val_accuracy: 0.7454\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8255 - val_loss: 0.6137 - val_accuracy: 0.7454\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8219 - val_loss: 0.6123 - val_accuracy: 0.7454\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8237 - val_loss: 0.6103 - val_accuracy: 0.7491\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.8273 - val_loss: 0.6129 - val_accuracy: 0.7454\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8201 - val_loss: 0.6081 - val_accuracy: 0.7454\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8255 - val_loss: 0.6130 - val_accuracy: 0.7454\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.8237 - val_loss: 0.6107 - val_accuracy: 0.7454\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.8237 - val_loss: 0.6179 - val_accuracy: 0.7454\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8219 - val_loss: 0.6112 - val_accuracy: 0.7491\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8273 - val_loss: 0.6076 - val_accuracy: 0.7454\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8201 - val_loss: 0.6146 - val_accuracy: 0.7417\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8273 - val_loss: 0.6136 - val_accuracy: 0.7454\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8201 - val_loss: 0.6058 - val_accuracy: 0.7491\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8309 - val_loss: 0.6118 - val_accuracy: 0.7454\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8219 - val_loss: 0.6147 - val_accuracy: 0.7491\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8219 - val_loss: 0.6063 - val_accuracy: 0.7454\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8291 - val_loss: 0.6104 - val_accuracy: 0.7454\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8237 - val_loss: 0.6138 - val_accuracy: 0.7454\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8255 - val_loss: 0.6125 - val_accuracy: 0.7491\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8237 - val_loss: 0.6151 - val_accuracy: 0.7454\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8309 - val_loss: 0.6089 - val_accuracy: 0.7454\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.8237 - val_loss: 0.6130 - val_accuracy: 0.7454\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8237 - val_loss: 0.6177 - val_accuracy: 0.7454\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8201 - val_loss: 0.6125 - val_accuracy: 0.7491\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8309 - val_loss: 0.6055 - val_accuracy: 0.7454\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8219 - val_loss: 0.6096 - val_accuracy: 0.7454\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.8291 - val_loss: 0.6201 - val_accuracy: 0.7454\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8255 - val_loss: 0.6138 - val_accuracy: 0.7454\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.8273 - val_loss: 0.6056 - val_accuracy: 0.7454\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8309 - val_loss: 0.6217 - val_accuracy: 0.7417\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8255 - val_loss: 0.6124 - val_accuracy: 0.7491\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8273 - val_loss: 0.6125 - val_accuracy: 0.7491\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8291 - val_loss: 0.6146 - val_accuracy: 0.7454\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8201 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8201 - val_loss: 0.6190 - val_accuracy: 0.7417\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8309 - val_loss: 0.6089 - val_accuracy: 0.7454\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8273 - val_loss: 0.6106 - val_accuracy: 0.7491\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8291 - val_loss: 0.6100 - val_accuracy: 0.7454\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8255 - val_loss: 0.6071 - val_accuracy: 0.7454\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8273 - val_loss: 0.6187 - val_accuracy: 0.7417\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8237 - val_loss: 0.6080 - val_accuracy: 0.7417\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8327 - val_loss: 0.6080 - val_accuracy: 0.7454\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8291 - val_loss: 0.6132 - val_accuracy: 0.7491\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8237 - val_loss: 0.6146 - val_accuracy: 0.7491\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8237 - val_loss: 0.6104 - val_accuracy: 0.7454\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8255 - val_loss: 0.6100 - val_accuracy: 0.7454\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8255 - val_loss: 0.6174 - val_accuracy: 0.7454\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8237 - val_loss: 0.6086 - val_accuracy: 0.7454\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8255 - val_loss: 0.6123 - val_accuracy: 0.7454\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8219 - val_loss: 0.6145 - val_accuracy: 0.7491\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8237 - val_loss: 0.6094 - val_accuracy: 0.7454\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8255 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8237 - val_loss: 0.6153 - val_accuracy: 0.7454\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8273 - val_loss: 0.6118 - val_accuracy: 0.7454\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8273 - val_loss: 0.6043 - val_accuracy: 0.7454\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8237 - val_loss: 0.6185 - val_accuracy: 0.7491\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8255 - val_loss: 0.6078 - val_accuracy: 0.7454\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8309 - val_loss: 0.6151 - val_accuracy: 0.7454\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8237 - val_loss: 0.6113 - val_accuracy: 0.7454\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8219 - val_loss: 0.6184 - val_accuracy: 0.7491\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8219 - val_loss: 0.6132 - val_accuracy: 0.7491\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8273 - val_loss: 0.6076 - val_accuracy: 0.7454\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8237 - val_loss: 0.6084 - val_accuracy: 0.7454\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8237 - val_loss: 0.6153 - val_accuracy: 0.7380\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8291 - val_loss: 0.6098 - val_accuracy: 0.7454\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8309 - val_loss: 0.6141 - val_accuracy: 0.7454\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8291 - val_loss: 0.6178 - val_accuracy: 0.7454\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8255 - val_loss: 0.6120 - val_accuracy: 0.7454\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8273 - val_loss: 0.6033 - val_accuracy: 0.7454\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8309 - val_loss: 0.6124 - val_accuracy: 0.7491\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8219 - val_loss: 0.6149 - val_accuracy: 0.7454\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8273 - val_loss: 0.6077 - val_accuracy: 0.7491\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8237 - val_loss: 0.6127 - val_accuracy: 0.7454\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8219 - val_loss: 0.6194 - val_accuracy: 0.7491\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8255 - val_loss: 0.6136 - val_accuracy: 0.7417\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8273 - val_loss: 0.6115 - val_accuracy: 0.7454\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8255 - val_loss: 0.6162 - val_accuracy: 0.7491\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8255 - val_loss: 0.6098 - val_accuracy: 0.7417\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8255 - val_loss: 0.6173 - val_accuracy: 0.7491\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8201 - val_loss: 0.6211 - val_accuracy: 0.7417\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8255 - val_loss: 0.6073 - val_accuracy: 0.7454\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8255 - val_loss: 0.6103 - val_accuracy: 0.7491\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8237 - val_loss: 0.6076 - val_accuracy: 0.7454\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8237 - val_loss: 0.6159 - val_accuracy: 0.7454\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8327 - val_loss: 0.6099 - val_accuracy: 0.7417\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8291 - val_loss: 0.6117 - val_accuracy: 0.7454\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8273 - val_loss: 0.6108 - val_accuracy: 0.7454\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8273 - val_loss: 0.6134 - val_accuracy: 0.7491\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8273 - val_loss: 0.6112 - val_accuracy: 0.7491\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8237 - val_loss: 0.6135 - val_accuracy: 0.7417\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8237 - val_loss: 0.6169 - val_accuracy: 0.7454\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8291 - val_loss: 0.6144 - val_accuracy: 0.7454\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8255 - val_loss: 0.6128 - val_accuracy: 0.7491\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8291 - val_loss: 0.6136 - val_accuracy: 0.7417\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8291 - val_loss: 0.6147 - val_accuracy: 0.7491\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8219 - val_loss: 0.6181 - val_accuracy: 0.7417\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8291 - val_loss: 0.6095 - val_accuracy: 0.7417\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8255 - val_loss: 0.6119 - val_accuracy: 0.7454\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8255 - val_loss: 0.6147 - val_accuracy: 0.7491\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8273 - val_loss: 0.6165 - val_accuracy: 0.7491\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8255 - val_loss: 0.6088 - val_accuracy: 0.7417\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8183 - val_loss: 0.6118 - val_accuracy: 0.7491\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8237 - val_loss: 0.6221 - val_accuracy: 0.7454\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8255 - val_loss: 0.6089 - val_accuracy: 0.7491\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8237 - val_loss: 0.6051 - val_accuracy: 0.7454\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8255 - val_loss: 0.6183 - val_accuracy: 0.7491\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8255 - val_loss: 0.6131 - val_accuracy: 0.7491\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8273 - val_loss: 0.6135 - val_accuracy: 0.7454\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8237 - val_loss: 0.6178 - val_accuracy: 0.7491\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8255 - val_loss: 0.6085 - val_accuracy: 0.7454\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8291 - val_loss: 0.6133 - val_accuracy: 0.7491\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8273 - val_loss: 0.6115 - val_accuracy: 0.7417\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8255 - val_loss: 0.6153 - val_accuracy: 0.7454\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8273 - val_loss: 0.6119 - val_accuracy: 0.7454\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8255 - val_loss: 0.6152 - val_accuracy: 0.7491\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8219 - val_loss: 0.6235 - val_accuracy: 0.7454\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8255 - val_loss: 0.6091 - val_accuracy: 0.7454\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8255 - val_loss: 0.6108 - val_accuracy: 0.7491\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8255 - val_loss: 0.6171 - val_accuracy: 0.7454\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8309 - val_loss: 0.6127 - val_accuracy: 0.7454\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8255 - val_loss: 0.6122 - val_accuracy: 0.7454\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8219 - val_loss: 0.6105 - val_accuracy: 0.7454\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8219 - val_loss: 0.6174 - val_accuracy: 0.7491\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8237 - val_loss: 0.6193 - val_accuracy: 0.7454\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8255 - val_loss: 0.6111 - val_accuracy: 0.7454\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.8273 - val_loss: 0.6197 - val_accuracy: 0.7454\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8219 - val_loss: 0.6191 - val_accuracy: 0.7454\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8291 - val_loss: 0.6092 - val_accuracy: 0.7454\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8237 - val_loss: 0.6151 - val_accuracy: 0.7491\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8237 - val_loss: 0.6100 - val_accuracy: 0.7454\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8237 - val_loss: 0.6159 - val_accuracy: 0.7491\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8273 - val_loss: 0.6068 - val_accuracy: 0.7454\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8219 - val_loss: 0.6194 - val_accuracy: 0.7491\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8273 - val_loss: 0.6112 - val_accuracy: 0.7491\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8255 - val_loss: 0.6123 - val_accuracy: 0.7491\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8291 - val_loss: 0.6084 - val_accuracy: 0.7454\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8255 - val_loss: 0.6172 - val_accuracy: 0.7454\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8237 - val_loss: 0.6144 - val_accuracy: 0.7454\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8255 - val_loss: 0.6151 - val_accuracy: 0.7454\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8237 - val_loss: 0.6123 - val_accuracy: 0.7417\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8255 - val_loss: 0.6097 - val_accuracy: 0.7454\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8219 - val_loss: 0.6110 - val_accuracy: 0.7491\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.8273 - val_loss: 0.6164 - val_accuracy: 0.7491\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8255 - val_loss: 0.6113 - val_accuracy: 0.7454\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8255 - val_loss: 0.6136 - val_accuracy: 0.7491\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8237 - val_loss: 0.6151 - val_accuracy: 0.7454\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8237 - val_loss: 0.6172 - val_accuracy: 0.7491\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8273 - val_loss: 0.6097 - val_accuracy: 0.7417\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8255 - val_loss: 0.6158 - val_accuracy: 0.7491\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8255 - val_loss: 0.6094 - val_accuracy: 0.7454\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8255 - val_loss: 0.6083 - val_accuracy: 0.7454\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8255 - val_loss: 0.6186 - val_accuracy: 0.7491\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8273 - val_loss: 0.6159 - val_accuracy: 0.7491\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8291 - val_loss: 0.6128 - val_accuracy: 0.7454\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8201 - val_loss: 0.6122 - val_accuracy: 0.7491\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8273 - val_loss: 0.6123 - val_accuracy: 0.7491\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8255 - val_loss: 0.6091 - val_accuracy: 0.7454\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8237 - val_loss: 0.6189 - val_accuracy: 0.7491\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8273 - val_loss: 0.6123 - val_accuracy: 0.7491\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8237 - val_loss: 0.6149 - val_accuracy: 0.7454\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8255 - val_loss: 0.6169 - val_accuracy: 0.7491\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8237 - val_loss: 0.6158 - val_accuracy: 0.7491\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8237 - val_loss: 0.6153 - val_accuracy: 0.7491\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8273 - val_loss: 0.6122 - val_accuracy: 0.7454\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8273 - val_loss: 0.6145 - val_accuracy: 0.7491\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8273 - val_loss: 0.6119 - val_accuracy: 0.7491\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8327 - val_loss: 0.6113 - val_accuracy: 0.7491\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8219 - val_loss: 0.6195 - val_accuracy: 0.7491\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8255 - val_loss: 0.6123 - val_accuracy: 0.7528\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8201 - val_loss: 0.6228 - val_accuracy: 0.7454\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8201 - val_loss: 0.6098 - val_accuracy: 0.7491\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8255 - val_loss: 0.6125 - val_accuracy: 0.7491\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.8255 - val_loss: 0.6165 - val_accuracy: 0.7454\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.8273 - val_loss: 0.6207 - val_accuracy: 0.7491\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8237 - val_loss: 0.6066 - val_accuracy: 0.7417\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8273 - val_loss: 0.6277 - val_accuracy: 0.7417\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8273 - val_loss: 0.6110 - val_accuracy: 0.7454\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.8255 - val_loss: 0.6165 - val_accuracy: 0.7454\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8273 - val_loss: 0.6150 - val_accuracy: 0.7491\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8273 - val_loss: 0.6119 - val_accuracy: 0.7491\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8255 - val_loss: 0.6176 - val_accuracy: 0.7454\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8255 - val_loss: 0.6176 - val_accuracy: 0.7491\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8237 - val_loss: 0.6171 - val_accuracy: 0.7417\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8291 - val_loss: 0.6142 - val_accuracy: 0.7454\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8327 - val_loss: 0.6082 - val_accuracy: 0.7454\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8309 - val_loss: 0.6186 - val_accuracy: 0.7417\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8237 - val_loss: 0.6190 - val_accuracy: 0.7491\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8273 - val_loss: 0.6117 - val_accuracy: 0.7491\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8273 - val_loss: 0.6176 - val_accuracy: 0.7491\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8255 - val_loss: 0.6157 - val_accuracy: 0.7454\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8237 - val_loss: 0.6144 - val_accuracy: 0.7491\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8255 - val_loss: 0.6163 - val_accuracy: 0.7491\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8273 - val_loss: 0.6101 - val_accuracy: 0.7454\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8273 - val_loss: 0.6155 - val_accuracy: 0.7454\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8291 - val_loss: 0.6158 - val_accuracy: 0.7491\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8201 - val_loss: 0.6044 - val_accuracy: 0.7491\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8165 - val_loss: 0.6270 - val_accuracy: 0.7454\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8255 - val_loss: 0.6110 - val_accuracy: 0.7491\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8237 - val_loss: 0.6130 - val_accuracy: 0.7491\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8273 - val_loss: 0.6195 - val_accuracy: 0.7491\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8237 - val_loss: 0.6226 - val_accuracy: 0.7454\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8219 - val_loss: 0.6187 - val_accuracy: 0.7491\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8255 - val_loss: 0.6230 - val_accuracy: 0.7454\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8273 - val_loss: 0.6090 - val_accuracy: 0.7454\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8273 - val_loss: 0.6148 - val_accuracy: 0.7454\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.8273 - val_loss: 0.6192 - val_accuracy: 0.7491\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8255 - val_loss: 0.6148 - val_accuracy: 0.7491\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8291 - val_loss: 0.6130 - val_accuracy: 0.7491\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8273 - val_loss: 0.6164 - val_accuracy: 0.7491\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8255 - val_loss: 0.6171 - val_accuracy: 0.7491\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8255 - val_loss: 0.6162 - val_accuracy: 0.7491\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8255 - val_loss: 0.6171 - val_accuracy: 0.7491\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8255 - val_loss: 0.6115 - val_accuracy: 0.7491\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.8291 - val_loss: 0.6171 - val_accuracy: 0.7491\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8255 - val_loss: 0.6142 - val_accuracy: 0.7491\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8273 - val_loss: 0.6202 - val_accuracy: 0.7454\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8273 - val_loss: 0.6174 - val_accuracy: 0.7491\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8255 - val_loss: 0.6119 - val_accuracy: 0.7528\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8273 - val_loss: 0.6132 - val_accuracy: 0.7491\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8273 - val_loss: 0.6188 - val_accuracy: 0.7380\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8255 - val_loss: 0.6138 - val_accuracy: 0.7454\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8237 - val_loss: 0.6275 - val_accuracy: 0.7380\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8273 - val_loss: 0.6145 - val_accuracy: 0.7528\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8291 - val_loss: 0.6136 - val_accuracy: 0.7417\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8237 - val_loss: 0.6237 - val_accuracy: 0.7454\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8219 - val_loss: 0.6183 - val_accuracy: 0.7491\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8255 - val_loss: 0.6112 - val_accuracy: 0.7454\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8291 - val_loss: 0.6126 - val_accuracy: 0.7491\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8273 - val_loss: 0.6230 - val_accuracy: 0.7491\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8255 - val_loss: 0.6257 - val_accuracy: 0.7454\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8291 - val_loss: 0.6036 - val_accuracy: 0.7491\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8327 - val_loss: 0.6178 - val_accuracy: 0.7491\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8219 - val_loss: 0.6153 - val_accuracy: 0.7454\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8237 - val_loss: 0.6148 - val_accuracy: 0.7491\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8255 - val_loss: 0.6186 - val_accuracy: 0.7417\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.8255 - val_loss: 0.6166 - val_accuracy: 0.7491\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8255 - val_loss: 0.6159 - val_accuracy: 0.7491\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8219 - val_loss: 0.6198 - val_accuracy: 0.7491\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8291 - val_loss: 0.6144 - val_accuracy: 0.7417\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8309 - val_loss: 0.6144 - val_accuracy: 0.7491\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8291 - val_loss: 0.6156 - val_accuracy: 0.7491\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8255 - val_loss: 0.6198 - val_accuracy: 0.7417\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8255 - val_loss: 0.6168 - val_accuracy: 0.7491\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8237 - val_loss: 0.6134 - val_accuracy: 0.7417\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8237 - val_loss: 0.6144 - val_accuracy: 0.7454\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.8237 - val_loss: 0.6202 - val_accuracy: 0.7454\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8255 - val_loss: 0.6101 - val_accuracy: 0.7417\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8255 - val_loss: 0.6246 - val_accuracy: 0.7454\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8255 - val_loss: 0.6124 - val_accuracy: 0.7528\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8219 - val_loss: 0.6165 - val_accuracy: 0.7417\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8255 - val_loss: 0.6179 - val_accuracy: 0.7491\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.8237 - val_loss: 0.6204 - val_accuracy: 0.7417\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8273 - val_loss: 0.6068 - val_accuracy: 0.7528\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8273 - val_loss: 0.6249 - val_accuracy: 0.7454\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8273 - val_loss: 0.6153 - val_accuracy: 0.7454\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8309 - val_loss: 0.6167 - val_accuracy: 0.7454\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8255 - val_loss: 0.6217 - val_accuracy: 0.7491\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8255 - val_loss: 0.6167 - val_accuracy: 0.7491\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.8273 - val_loss: 0.6195 - val_accuracy: 0.7491\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8237 - val_loss: 0.6206 - val_accuracy: 0.7491\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8273 - val_loss: 0.6133 - val_accuracy: 0.7491\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.8345 - val_loss: 0.6180 - val_accuracy: 0.7491\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8255 - val_loss: 0.6176 - val_accuracy: 0.7491\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8273 - val_loss: 0.6127 - val_accuracy: 0.7491\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.8291 - val_loss: 0.6174 - val_accuracy: 0.7491\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8255 - val_loss: 0.6194 - val_accuracy: 0.7417\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8291 - val_loss: 0.6132 - val_accuracy: 0.7454\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.8291 - val_loss: 0.6183 - val_accuracy: 0.7491\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8255 - val_loss: 0.6210 - val_accuracy: 0.7491\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8237 - val_loss: 0.6099 - val_accuracy: 0.7528\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8237 - val_loss: 0.6180 - val_accuracy: 0.7491\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8273 - val_loss: 0.6165 - val_accuracy: 0.7491\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8291 - val_loss: 0.6105 - val_accuracy: 0.7454\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8219 - val_loss: 0.6231 - val_accuracy: 0.7454\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8255 - val_loss: 0.6145 - val_accuracy: 0.7454\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8273 - val_loss: 0.6172 - val_accuracy: 0.7491\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.8291 - val_loss: 0.6147 - val_accuracy: 0.7454\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8201 - val_loss: 0.6222 - val_accuracy: 0.7454\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8237 - val_loss: 0.6191 - val_accuracy: 0.7528\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8237 - val_loss: 0.6152 - val_accuracy: 0.7528\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8255 - val_loss: 0.6230 - val_accuracy: 0.7454\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8255 - val_loss: 0.6122 - val_accuracy: 0.7491\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8255 - val_loss: 0.6212 - val_accuracy: 0.7454\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8237 - val_loss: 0.6232 - val_accuracy: 0.7454\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8255 - val_loss: 0.6162 - val_accuracy: 0.7491\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8237 - val_loss: 0.6302 - val_accuracy: 0.7454\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8273 - val_loss: 0.6093 - val_accuracy: 0.7528\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8255 - val_loss: 0.6205 - val_accuracy: 0.7491\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.8273 - val_loss: 0.6156 - val_accuracy: 0.7491\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8255 - val_loss: 0.6211 - val_accuracy: 0.7454\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8291 - val_loss: 0.6141 - val_accuracy: 0.7454\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8273 - val_loss: 0.6160 - val_accuracy: 0.7491\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8237 - val_loss: 0.6251 - val_accuracy: 0.7454\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8273 - val_loss: 0.6098 - val_accuracy: 0.7491\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8327 - val_loss: 0.6210 - val_accuracy: 0.7491\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8237 - val_loss: 0.6186 - val_accuracy: 0.7491\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8237 - val_loss: 0.6195 - val_accuracy: 0.7454\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8237 - val_loss: 0.6201 - val_accuracy: 0.7491\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8291 - val_loss: 0.6105 - val_accuracy: 0.7454\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8291 - val_loss: 0.6264 - val_accuracy: 0.7454\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8255 - val_loss: 0.6141 - val_accuracy: 0.7528\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8237 - val_loss: 0.6150 - val_accuracy: 0.7528\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8219 - val_loss: 0.6226 - val_accuracy: 0.7454\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8273 - val_loss: 0.6144 - val_accuracy: 0.7454\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8273 - val_loss: 0.6209 - val_accuracy: 0.7417\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8255 - val_loss: 0.6094 - val_accuracy: 0.7528\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8201 - val_loss: 0.6262 - val_accuracy: 0.7417\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8255 - val_loss: 0.6171 - val_accuracy: 0.7491\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8219 - val_loss: 0.6171 - val_accuracy: 0.7491\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8273 - val_loss: 0.6192 - val_accuracy: 0.7417\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8237 - val_loss: 0.6224 - val_accuracy: 0.7491\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8273 - val_loss: 0.6147 - val_accuracy: 0.7491\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8273 - val_loss: 0.6197 - val_accuracy: 0.7491\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8255 - val_loss: 0.6216 - val_accuracy: 0.7491\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8165 - val_loss: 0.6160 - val_accuracy: 0.7528\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8255 - val_loss: 0.6209 - val_accuracy: 0.7491\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8237 - val_loss: 0.6222 - val_accuracy: 0.7454\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8273 - val_loss: 0.6161 - val_accuracy: 0.7491\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8219 - val_loss: 0.6157 - val_accuracy: 0.7528\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8273 - val_loss: 0.6202 - val_accuracy: 0.7417\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8273 - val_loss: 0.6148 - val_accuracy: 0.7491\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8237 - val_loss: 0.6234 - val_accuracy: 0.7454\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8255 - val_loss: 0.6140 - val_accuracy: 0.7454\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8273 - val_loss: 0.6180 - val_accuracy: 0.7528\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8237 - val_loss: 0.6166 - val_accuracy: 0.7491\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8273 - val_loss: 0.6194 - val_accuracy: 0.7454\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8273 - val_loss: 0.6163 - val_accuracy: 0.7491\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8237 - val_loss: 0.6176 - val_accuracy: 0.7454\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8291 - val_loss: 0.6226 - val_accuracy: 0.7417\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8309 - val_loss: 0.6144 - val_accuracy: 0.7454\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8273 - val_loss: 0.6234 - val_accuracy: 0.7417\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8237 - val_loss: 0.6204 - val_accuracy: 0.7491\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8255 - val_loss: 0.6198 - val_accuracy: 0.7528\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8255 - val_loss: 0.6067 - val_accuracy: 0.7528\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8237 - val_loss: 0.6208 - val_accuracy: 0.7491\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8237 - val_loss: 0.6183 - val_accuracy: 0.7491\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8237 - val_loss: 0.6185 - val_accuracy: 0.7491\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8309 - val_loss: 0.6172 - val_accuracy: 0.7380\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8255 - val_loss: 0.6166 - val_accuracy: 0.7491\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8273 - val_loss: 0.6219 - val_accuracy: 0.7454\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8255 - val_loss: 0.6209 - val_accuracy: 0.7491\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8291 - val_loss: 0.6162 - val_accuracy: 0.7380\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8273 - val_loss: 0.6168 - val_accuracy: 0.7454\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8237 - val_loss: 0.6214 - val_accuracy: 0.7454\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8309 - val_loss: 0.6181 - val_accuracy: 0.7417\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8237 - val_loss: 0.6206 - val_accuracy: 0.7491\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8273 - val_loss: 0.6175 - val_accuracy: 0.7491\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8273 - val_loss: 0.6222 - val_accuracy: 0.7454\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8255 - val_loss: 0.6143 - val_accuracy: 0.7528\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8291 - val_loss: 0.6187 - val_accuracy: 0.7491\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8273 - val_loss: 0.6211 - val_accuracy: 0.7454\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8273 - val_loss: 0.6173 - val_accuracy: 0.7528\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8291 - val_loss: 0.6170 - val_accuracy: 0.7491\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8291 - val_loss: 0.6250 - val_accuracy: 0.7454\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8273 - val_loss: 0.6175 - val_accuracy: 0.7491\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8291 - val_loss: 0.6202 - val_accuracy: 0.7417\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8291 - val_loss: 0.6231 - val_accuracy: 0.7454\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8237 - val_loss: 0.6193 - val_accuracy: 0.7491\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8237 - val_loss: 0.6203 - val_accuracy: 0.7454\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8255 - val_loss: 0.6210 - val_accuracy: 0.7454\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8273 - val_loss: 0.6225 - val_accuracy: 0.7454\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8273 - val_loss: 0.6206 - val_accuracy: 0.7491\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8273 - val_loss: 0.6175 - val_accuracy: 0.7491\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8273 - val_loss: 0.6189 - val_accuracy: 0.7491\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8291 - val_loss: 0.6202 - val_accuracy: 0.7491\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8273 - val_loss: 0.6190 - val_accuracy: 0.7491\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8309 - val_loss: 0.6154 - val_accuracy: 0.7491\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8237 - val_loss: 0.6219 - val_accuracy: 0.7417\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8273 - val_loss: 0.6180 - val_accuracy: 0.7491\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8237 - val_loss: 0.6255 - val_accuracy: 0.7454\n"
     ]
    }
   ],
   "source": [
    "# Create a model with a single hidden layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu, input_dim=x_train.shape[1]),\n",
    "    keras.layers.Dense(len(phonemes), activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=1000, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training results\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6255014538764954\n",
      "Validation accuracy: 0.7453874349594116\n"
     ]
    }
   ],
   "source": [
    "# Validation model\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "Increase the number of features to include \"F3\" and \"F4\" and rerun the experiments. Try also adding the bandwidths (\"B1\"-\"B4\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Change the number of nodes in the hidden layer and see how the results change. Try using dropout, and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Add multiple layers to the network and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "Use the data to predict the gender of the speaker. Try including the format bandwidths as features as well (\"B1\"-\"B4\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
